## 8.7 更多细节（*Further Details*）

在这一节中，我们将总结数据和模型的其余几个细节，首先是数据。由于我们提出的算法是有监督的，所以标注数据对于训练和测试是至关重要的。现在我们有各种各样的数据集用于词性标注和 NER。在撰写本文时，Universal Dependencies（UD）数据集 (Nivre et al., 2016b)[^1] 有 92 种语言的 POS 标注语料，Penn Treebanks 也有英文、中文和阿拉伯文版本。OntoNotes NER 语料库也有英文、中文和阿拉伯文版本 (Hovy et al, 2006)[^2]。同时也有在特定领域的 NER 语料库，例如生物医学领域 (Bada et al., 2012)[^3] 和文学文本 (Bamman et al., 2019)[^4]。

### 8.7.1 双向性（*Bidirectionality*）

上述 CRF 和 HMM 架构的一个问题是，这些模型是完全从左到右运行的。虽然维特比算法允许当前决策间接地受到未来决策的影响，但如果预测单词 $w_i$ 的标签时能够直接使用未来标签 $t_{i+1}$ 和 $t_{i+2}$ 的信息，那将会有更大的帮助。

另外，任何序列模型都可以通过使用多个通道变成一个双向模型。例如，第一个通道只使用左边词的词性特征。在第二个通道中，可以使用所有单词的标签，包括右边的单词。另外，标注器也可以运行两次，一次从左到右，一次从右到左。在维特比解码中，标注器会选择两个序列中得分较高的序列（从左到右或从右到左）。双向模型对于神经模型来说是很常用的，正如我们将在第九章介绍的 biLSTM 模型中看到的那样。

### 8.7.2 基于规则的方法（*Rule-based Methods*）

虽然机器学习（神经网络或 CRF）序列模型是学术研究中的常态，但是商业化的 NER 方法通常是基于列表和规则的组合，以及少量的监督机器学习 (Chiticariu et al., 2013)[^5]。例如，在 IBM 的 SystemT 架构中，用户使用一种查询语言指定标注任务的声明式约束，这种查询语言包括正则表达式、字典、语义约束和其他运算符，系统将其编译成一个高效的提取器 (Chiticariu et al., 2018)[^6]。

一种常见的方法是对文本进行反复的规则处理，从精度很高但召回率很低的规则开始。在随后的阶段，使用机器学习方法，再把第一次的输出考虑进去。

1. 首先，使用高精度的规则来标记明确的无争议的实体提及。
2. 然后，匹配搜索上述步骤得到的实体子串。
3. 使用特定应用的名称列表来寻找可能的特定领域实体提及。
4. 最后，使用上述抽取到的实体作为额外的特征，应用监督序列标注技术。

基于规则的方法也是最早的词性标注方法。基于规则的标注器，如 English Constraint Grammar 系统 (Karlsson et al. 1995[^7], Voutilainen 1999[^8])，使用 20 世纪 50 年代和 60 年代发明的两段式方法：一个具有数以万计的词干条目的形态分析器返回一个词的所有词性。然后，对输入的句子应用一大套成千上万的约束条件，以排除与上下文不一致的词性。

### 8.7.3 形态丰富语言的词性标注（*POS Tagging for Morphologically Rich Languages*）

在处理像捷克语、匈牙利语和土耳其语这样具有丰富形态的语言时，有必要对标注算法进行增强。

这些富有成效的构词过程导致这些语言的词汇量很大：一个 25 万字的匈牙利语语料库的词型（*word type*）量是同等规模的英语语料库的两倍多 (Oravecz and Dienes, 2002)[^9]，而一个有 1000 万字的土耳其语语料库的词型量是同等规模的英语语料库的四倍 (Hakkani-Tür et al., 2002)[^10]。大词汇量意味着有许多未登录词，而这些未登录词在各种语言（包括捷克语、斯洛文尼亚语、爱沙尼亚语和罗马尼亚语）中都会造成明显的性能下降 (Hajič, 2000)[^11]。

高度屈折（*Inflection*）的语言也比用词形态（*word morphology*）编码的英语有更多的信息，如大小写（名词、指代词、属词）或性别（阳性、阴性）。因为这些信息对于像 parsing 和指代消歧这样的任务是很重要的。形态丰富语言的词性标注器，需要用大小写和性别信息来预测单词词性。因此，形态丰富语言的标签集是形态学标签的序列，而不是单一的原始标签。下面是一个土耳其语的例子，在这个例子中，*izin* 这个词有三种可能的形态/词性标签和含义 (Hakkani-Tür et al., 2002)[^10]：

1. Yerdeki **izin** temizlenmesi gerek. / iz + Noun+A3sg+Pnon+Gen  
   **The trace** on the floor should be cleaned.
2. Ü zerinde parmak **izin** kalmis¸ / iz + Noun+A3sg+P2sg+Nom  
   **Your** finger **print** is left on (it).
3. Içeri girmek için **izin** alman gerekiyor. / izin + Noun+A3sg+Pnon+Nom  
   You need **permission** to enter.


[^1]: Nivre, J., de Marneffe, M.-C., Ginter, F., Goldberg, Y., Hajiˇc, J., Manning, C. D., McDonald, R., Petrov, S., Pyysalo, S., Silveira, N., Tsarfaty, R., and Zeman, D. (2016b). Universal Dependencies v1: A multilingual treebank collection. LREC.  
[^2]: Hovy, E. H., Marcus, M. P., Palmer, M., Ramshaw, L. A., and Weischedel, R. (2006). Ontonotes: The 90% solution. HLT-NAACL.  
[^3]: Bada, M., Eckert, M., Evans, D., Garcia, K., Shipley, K., Sitnikov, D., Baumgartner, W. A., Cohen, K. B., Verspoor, K., Blake, J. A., and Hunter, L. E. (2012). Concept annotation in the craft corpus. BMC bioinformatics 13(1), 161.  
[^4]: Bamman, D., Popat, S., and Shen, S. (2019). An annotated dataset of literary entities. NAACL HLT.  
[^5]: Chiticariu, L., Li, Y., and Reiss, F. R. (2013). Rule-Based Information Extraction is Dead! Long Live Rule-Based Information Extraction Systems!. EMNLP.  
[^6]: Chiticariu, L., Danilevsky, M., Li, Y., Reiss, F., and Zhu, H. (2018). SystemT: Declarative text understanding for enterprise. NAACL HLT, Vol. 3.  
[^7]: Karlsson, F., Voutilainen, A., Heikkil¨a, J., and Anttila, A. (Eds.). (1995). Constraint Grammar: A Language-Independent System for Parsing Unrestricted Text. Mouton de Gruyter.  
[^8]: Voutilainen, A. (1999). Handcrafted rules. van Halteren, H. (Ed.), Syntactic Wordclass Tagging, 217–246. Kluwer.  
[^9]: Oravecz, C. and Dienes, P. (2002). Efficient stochastic part-of-speech tagging for Hungarian. LREC.  
[^10]: Hakkani-Tür, D., Oflazer, K., and T¨ur, G. (2002). Statistical morphological disambiguation for agglutinative languages. Journal of Computers and Humanities 36(4), 381–410.  
[^11]: Hajič, J. (2000). Morphological tagging: Data vs. dictionaries. NAACL. Seattle.
